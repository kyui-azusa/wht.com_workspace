 

 



|      |                                                              |                                                              |      |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---- |
|      | ![校名](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image003.jpg) |                                                              |      |
|      |                                                              |                                                              |      |
|      |                                                              | ![校徽](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg) |      |

 



 

 

 

 

 

 

 

 

 



**强国之路践行课题报告**

| **课题名称：** **大模型辅助年报阅读——** **信息膨胀识别及信息含量探究** |
| ------------------------------------------------------------ |
| **项目负责人：**    **乔怡玮**                               |
| **项目成员：** **乔怡玮** **万浩同** **郑景桐**              |
| **指导教师：**   **罗妍** **教授**                           |

 

 

 

 

 

 

 

 

**摘要：**

企业年报是投资者获取企业经营信息的重要来源，但长期以来，企业信息披露中的过载现象成为一个重要的问题。企业的披露的信息越来越长，也越来越复杂，使得投资者在信息处理方面付出的成本不断增加，而大模型的长文本分析能力在辅助投资者进行信息处理方面潜力巨大。本文探讨了大语言模型为公司年报中的管理层讨论与分析（MD&A）部分撰写摘要的能力并评估其有效性，重点研究了KIMI、文心一言和通义千问三个中国主要的语言模型。本文选取上海贝岭股份有限公司进行案例分析，分别利用三种模型生成其近10年的MD&A摘要，从而分析不同语言模型在辅助信息处理方面的表现。通过比较摘要和相应源文本MD&A的文本相似度，我们验证了语言模型生成的摘要确实是基于所传入的文本。为评估摘要的准确性，本文对生成的摘要进行了情绪分析，并与原文的情绪比进行对比。研究发现，大语言模型倾向于放大文本中的情绪特征，但这种情绪倾向并未与公司业绩（如销售额、利润和增长率）表现出显著的相关性。此外，通过引入“信息膨胀”的概念，在认为公司倾向于利用冗长的年报文本内容来掩盖其糟糕的业绩的假设下，分析不同摘要的冗长程度与公司业绩之间的关系。经相关性分析结果表明，KIMI的摘要冗长程度与公司业绩表现呈正相关，相关系数达0.4798，显示出其在文本概括方面的准确。相比之下，文心一言和通义千问的表现较差。本文的研究表明，大语言模型对年报文本的概括力较强，但目前在帮助投资者准确识别企业经营情况方面仍具有一定的局限性，存在较大的提升空间。

 

**关键词：**信息膨胀；大语言模型；摘要生成；文本分析

 

**一．引言**

公司年报一直都是投资者对公司业绩的首要获取渠道。2022年11月起，Chat GPT发布，更多人选择利用这一强大的大语言模型快速通读公司的经营状况。但对于大语言模型在信息处理的研究吸引了越来越多人的关注，例如，Alex.G.Kim和他的团队在2024年发表文章研究Chat GPT能否有效帮助投资者处理信息。

本文参照Kim的研究，分别利用KIMI、文心一言、通义千问三种语言模型对在中国A股市场上市的上海贝岭有限公司的近10年年报的MD&A进行概括并总结出摘要。这三个语言模型能够以简洁、有效和人类可理解的方式总结相关文本信息。本文后续的研究都是基于这十年的摘要，通过对其本身和它与公司业绩的关系的分析得出这三个模型的概括能力，并比较得到哪个模型的概括能力更好。

我们将重点放在管理层讨论与分析（MD&A）上。我们先提取了上海贝岭近十年的MD&A。然后，我们指示语言模型生成每个文档的不受限制的摘要，而不参考其他文档或外部来源的信息。我们发现，与原始文档的平均长度相比，KIMI（文心一言、通义千问）对MD&A的无约束摘要的平均长度约为700-900字（1000-1500字）。这一结果表明，以上语言模型在概括的时候总能提取出MD&A中最精炼的部分。但如此精炼的摘要是否仍然具有信息量？我们的研究将聚焦在这一问题。

因此，我们进而对总结得到的摘要进行情绪分析，计算出每年的正负情绪比。通过与原文正负情绪比的对比来验证摘要是否能够准确概括原文想表达的情绪。结果发现大语言模型会倾向于放大文本情绪特征。我们同时通过可视化摘要正负情绪比和公司几项业绩指标（销售额、利润及相应增长率），观察其是否有明显相关性，来验证摘要的正负情绪比这方面是否可以反映公司业绩。与我们预期的一样，由于大语言模型倾向放大情绪特征，结果得到两者并无显著的相关性。

因为我们的目标是探究大语言模型能否有效帮助利益相关者准确识别企业的经营情况。以迪士尼于2022年11月举行的电话会议为例，这通电话引起了媒体的广泛报道，因为迪士尼首席执行官被指责回避和淡化公司的糟糕业绩，这一争议导致他在两周后被解雇。这次通话还花了相当多的时间讨论不太相关的话题，比如100周年庆典。由此我们引入了冗长程度（Bloat）的定义，认为其与词数、平均句子长度、停用词比例、词汇多样性以及Flesch可读性得分。我们认为Bloat（冗长程度越大则Bloat越小）与企业业绩指标应该呈正相关。

根据该定义，我们计算了十年摘要的Bloat，并与前文提到的一些指标进行相关性分析。结果表明，KIMI的摘要文本的冗长程度确实与公司业绩表现呈正相关。这表明KIMI在文本信息概括方面的表现非常好，与之相反的则是文心一言和通义千问，其在本文所采用的方法下验证出来的表现并不理想。

 

**二.** **文献综述**

企业年报是投资者获取企业经营信息的重要来源。但长期以来，企业信息披露中的过载现象成为一个重要的问题，企业的披露的信息越来越长，也越来越复杂（Loughran and McDonald, 2014a; Dyer et al., 2017）。研究表明，在1996年到2013年期间，美国公司年报长度的中位数增加了100%以上，同时出现了模板化内容增加、冗余增加以及可读性和有效信息相对量的减少（Dyer et al., 2017）。年报文本信息的有效性降低的一个可能的原因是管理层通过增加无关紧要的信息含量来模糊负面信息（Li, 2008）。‌[美国证券交易委员会](https://www.baidu.com/s?tn=15007414_10_pg&wd=美国证券交易委员会&usm=2&ie=utf-8&rsv_pq=b52c4bad000184f8&oq=SEC是什么机构&rsv_t=e35cvtUxvFru3HMdfk3oZcbZceHrLhA3YiTNZFqB2D44OdapaXkVBlZtYXZEpq0wLZpgs+U&rsv_dl=re_dqa_generate&sa=re_dqa_generate)（SEC）也对MD&A披露的信息性一再表示担忧（Brown and Tucker, 2011）。

投资者在信息处理方面往往需要付出很大的成本（Sims, 2003; Blankespoor et al., 2020; Cohen et al., 2020），而不断增加的年报文本长度进一步增加了这一成本。目前，随着人工智能的迅速发展，大模型强大的自然语言处理能力在帮助投资者降低年报信息处理成本方面潜力巨大，ChatGPT等生成型人工智能工具可以从根本上改变投资者处理信息的方式。最新研究发现，通过GPT-3.5-Turbo生成的无约束的摘要明显短于原始文本，且其中的情感倾向会被放大。同时，通过研究股市对披露信息的反应，发现膨胀的信息披露与不利的资本市场后果（如较低的价格效率和更高的信息不对称性）有关。总的来说，该研究表明生成式人工智能为具有信息处理约束的投资者增加了相当大的价值（Kim et al., 2023）。

 

**三．理论假设**

本文基于Kim的研究，采用了以下假设：

1.MD&A中的正负情绪比能够反映企业业绩情况。

2.企业倾向于利用在年报中堆积大量的无用信息（即冗长程度）以掩盖其糟糕的业绩表现。

3.语言模型对文本概括的准确性可用文本相似度来衡量。

**四．****实证分析**

**4.1** **数据来源**

**4.1.1****样本选取**

本课题选取A股上市公司上海贝岭（600171）进行案例研究。上海贝岭公司上市时间久，具有充足的年报文本数据可供分析，同时其所在的芯片行业具有国家战略性意义，符合强国之路课程课题的价值导向，是比较合意的研究对象。我们从上交所网站下载了上海贝岭公司近十年的年报，从中提取出管理层讨论与分析（MD&A）部分作为原始文本。

**4.1.2** **通过大模型生成摘要**

我们分别使用Kimi，通义千问，文心一言三个主要的国产大模型对年报MD&A文本生成摘要。我们要求生成的摘要满足“不改变原意，不得减少原报告的信息含量”的要求，但不对输出长度进行限制，具体提示词如下：

 



|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![文本框: “你的专职工作是为企业年报进行摘要，以使投资人能更加方便且充分地了解企业的经营信息，你可以通过将缺乏信息含量的内容进行缩写来对信息进行浓缩和概括，但不能直接将部分信息和内容省去，撰写的摘要必须满足‘不改变原意，不得减少原报告的信息含量’的要求，此外你的摘要没有篇幅限制。下面请为这篇年报内容生成一份符合要求的摘要：”  ](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image005.gif) |

 



 

 

 

 

 



通过三个大模型对十份年报MD&A文本进行摘要，我们共得到30份摘要结果。

**4.1.3** **摘要结果初步讨论**

通过将生成的摘要文本与原文本进行比较，我们发现大模型年报文本的概括力较强（摘要文本长度为原文本的10%-20%），且摘要逻辑性可读性较好，基本保留了关键信息，下图为部分原文本与相应摘要输出结果对比，其中相同颜色的文本对应摘要前后的同一信息。

 

   **图1****：2023****年报中的MD&A****文本**

![img](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image007.jpg)

**图2****：Kimi****生成的摘要**

![img](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image009.jpg)

**图3****：文心一言生成的摘要**

![img](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image011.jpg)

**图4****：通义千问生成的摘要**

![img](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image013.jpg)

从这部分内容的摘要对比结果可以直观看出，Kimi较为准确精炼地概括出了主要信息，而文心一言出现了部分信息的缺失，通义千问的输出结果明显长于其他两个，概括性相对较差。但我们通过个人感受判断信息的重要程度，从而对其摘要能力做出直接评判的方式缺乏科学性，下面我们将通过实证分析进一步进行研究。

 

**4.2** **情绪分析**

**4.2.1 FinBERT****模型的使用**

**（1****）模型背景**

自然语言处理（Natural Language Processing, NLP）近年发展迅速，在多行业多领域中逐渐得到了广泛运用，其中 BERT (Bidirectional Encoder Representations from Transformers) 作为金融领域的一大预训练语言模型，已然能够系统地分析金融相关文本，并且得出具有一定指导性的结论。然而，尽管通用 BERT 在对相关行业不同性质的文本的处理上颇有成效，但其在金融领域依旧受到如下限制：金融文本中常包含大量金融术语（如“净利润增长”），通用 BERT 并不难充分捕捉这些特性；特定文本中的情绪流露往往较为隐晦（如“涨幅逐渐趋于平稳”通常带有负面情绪），而通用BERT模型难以识别这些隐晦信息。为了解决现有模型的限制，使其对于金融文本的分析具有更多正面效益，由Prosus AI团队开发的FinBERT 着重对金融语料进行了深度学习，以提升模型在情绪分析和处理效率方面的表现。

自然语言处理技术在深度学习时代经历了两大重要阶段。第一阶段是在2013年逐渐兴起，以 Word2Vec为代表的的词向量技术；第二阶段则是在 2018 年以 BERT 为代表的深度预训练语言模型（Pre-trained Language Models）。一方面，以 BERT为代表的深度预训练模型在包括文本分类、命名实体识别、问答等几乎所有的子领域达到了新的境界；另一方面，也大幅减少了 NLP 算法工程师的工作负担，为具体应用提供了性能卓越的基线模型。

**（2****）模型原理**

FinBERT模型的基本原理基于已有的BERT模型，额外针对金融领域语料的进行了预训练和微调，以提升其在金融文本处理中的表现。BERT作为一种双向语言模型，利用Transformer的多头自注意力机制同时捕捉上下文信息，其双向编码器能够生成动态的词表示，从而表示句子中词语的多义性和上下文依赖性。

在 BERT 的基础上，FinBERT 在包含金融新闻、公司财报和投行分析报告等大规模金融语料上进行了加强训练。其预训练阶段采用掩码语言模型（Masked Language Model, MLM）任务，通过随机遮蔽部分输入词汇并预测被遮蔽词汇，从而增强对金融术语及上下文间的关联的理解。完成预训练和微调后，FinBERT 能高效地将文本情绪分为正面（Positive）、中性（Neutral）和负面（Negative）三类，并量化分析各类情绪在文本中的占比。这一模型通过深度学习文本语义特征，能够捕捉隐藏的情绪表达，从而弥补通用模型的不足。

**（3****）训练语料**

FinBERT 的预训练语料覆盖金融领域的多类文本资源，包括金融财经新闻、研究报告与公司公告以及金融类百科词条。其中，金融财经新闻主要来自于主流媒体报道，涵盖近十年内约100万篇相关报道；研究报告与公司公告则来源于500多家国内外研究机构，覆盖9000家上市公司，涉及150多种不同类型的报告，总量约200万篇；金融类百科词条则从Wiki等平台采集，总计约100万条。在导师的指导下，这些语料经过筛选与规范化预处理，最终形成了约30亿Tokens的训练语料库。

对于上述三类语料，经由指导老师的指导，我们对于各类语料的重要部分进行筛选、预处理之后得到最终用于模型训练的语料，共包含约30亿Tokens，训练文本量超过了原生中文BERT的训练规模。

**4.2.2** **通过FinBERT****模型分析财报中的情绪**

**（1****）部分得分结果**

 

**图5.** **不同文本的情绪评分占比**

| **Year** | **source** | **Neutral (%)** | **Positive (%)** | **Negative (%)** | **Positive/Negative** |
| -------- | ---------- | --------------- | ---------------- | ---------------- | --------------------- |
| **2014** | 原始文本   | 79.6            | 13.7             | 6.7              | 2.04                  |
|          | 通义千问   | 77.25           | 12.9             | 9.85             | 1.31                  |
|          | 文心一言   | 76.65           | 14.15            | 9.15             | 1.55                  |
|          | Kimi       | 86.75           | 7.6              | 5.65             | 1.35                  |
| **2015** | 原始文本   | 79.47           | 14.44            | 6.09             | 2.37                  |
|          | 通义千问   | 80.55           | 13.88            | 5.63             | 2.47                  |
|          | 文心一言   | 78              | 15.5             | 6.57             | 2.36                  |
|          | Kimi       | 81.8            | 13.15            | 5.1              | 2.58                  |
| **2020** | 原始文本   | 75.83           | 17.53            | 6.65             | 2.63                  |
|          | 通义千问   | 84.75           | 9.6              | 5.6              | 1.71                  |
|          | 文心一言   | 78.83           | 14.47            | 6.7              | 2.16                  |
|          | Kimi       | 85.75           | 8.25             | 6                | 1.38                  |

 

**（2****）数据结果说明**

原始财报文本以及总结性文本中的中性情绪在所有年份中占比最高（如 2014 年为 79.6%，2020 年为 75.83%），表明财报整体使用了中性的词汇，呈现了较为中立的情绪。在绝大多数财报中正面情绪比例通常高于负面情绪，体现了财报的撰写中多使用正面的词汇，并且负面用语较少或者不够显著。例如，2014 年原始文本的正面情绪为 13.70%，负面情绪为 6.70%，正负比例为 2.04。

关于不同大语言模型的数据分析：

- 通义千问： 在大多数年份中，通义千问生成的文本正面情绪略低于原始文本，但负面情绪比例有所增加，例如 2014 年负面情绪为 9.85%，高于原始文本的 6.70%。
- 文心一言： 文心一言的情绪分布较为均衡，但在部分年份中正面情绪占比高于其他模型，例如 2015 年正面情绪为 15.50%。
- Kimi： Kimi 生成的文本倾向于降低正面和负面情绪的比重，增加中性情绪比例。例如，2020 年正面情绪为 8.25%，远低于原始文本的 17.53%。

通过正负情绪比例（Positive/Negative）部分可以观察情绪的显著性：原始文本的正负比例通常较高（如 2015 年为 2.37），而通义千问的正负比例较低（2015 年为 2.47）。文心一言和 Kimi 在部分年份中表现出较高的情绪平衡性，正负比例接近 2 或以下。

**（3****）数据总结**

通过上述分析可以看出，不同文本的情绪分布存在一定差异。尤其是在大模型生成的概括性文本中，正负情绪比例更接近或有所突出，这表明大模型可能在概括过程中放大了情绪特征。

 

**4.3** **统计分析**

**4.3.1** **相似度对比**

在此部分中，我们将KIMI对MD&A的摘要作为分析的文本。在假设其概括能力恒定的条件下，我们发现其在对字数在4000至12000范围内的原始文本概括的时候，输出内容保持在900-1000字（其他语言模型在1100-1500字），这种现象可能由两个原因导致：一种是在语言模型内置算法中对长文本的概括在未加强制指令的条件下有该字数范围限制；另一种则是语言模型可以准确提取出MD&A中的有效信息。

于是我们选择采用比对文本相似度（TS）的方法来验证其概括文本的准确性。TS指基于词袋模型的相似度，通常是计算文本中的词项频率。本文采用余弦相似度，衡量的是两个向量的夹角。它表示了两个向量的相似程度，值越接近 1 表示两个文本越相似，值越接近 0 表示两个文本越不相似。

结果如图：[[1\]](#_msocom_1) 

**图6****：KIMI****生成的摘要间的文本相似度**

![d8cb7ed3e47772c1ee6acd7c310660a](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image015.gif)

 

**图7****：原始MD&A****文本间的文本相似度**

 

![cd1d582c7fc0da2364142419b71336f](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image017.gif)

由图可以看出，KIMI模型生成的摘要之间的TS与原始MD&A文本之间的TS变化率呈正相关，因此可以表明KIMI的概括能力是基于文本的，而并不是按照某种固定算法对不同文本进行类似的处理。

**4.3.2** **数据可视化**

在验证了KIMI概括能力的可靠性之后，我们先对该公司的运营情况进行数据可视化处理，以便于更好的结合文本分析，其情况如图所示：

 

**图8****：公司年销售总额和年利润总额**![5daaf0ec0a13e270e2cef97e2ed2bd7](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image019.gif)

**图9****：公司年销售增长率和年利润增长率**

![c7f72d162baf60b422ed6b444da6252](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image021.gif)

 

 

随后，我们基于情绪正负比，将其与公司年销售总额和年利润增长率进行比较，观察其是否正相关，从而验证在“公司运营情况好代表MD&A中正面情绪高”这一假设下，KIMI对文本情绪的概括是否可靠。结果如图所示。

 

**图10****：情绪正负比与年销售总额**![IMG_256](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image023.gif)

 

 

**图11****：情绪正负比与年利润增长率**

![IMG_256](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image025.gif)

 

由图我们可以得到，KIMI对文本想要表达的情绪的概括能力是十分有限的，这也印证了前文提到的“语言模型倾向放大情绪特征”。

 

**4.3.3 Bloat****分析**

我们不能仅从情绪正负比这一角度否定KIMI的概括能力，这是因为在很多情况下上述条件是不成立的，如“研发成本正在降低”会被总结为负面情绪，但很明显这是正面的语句。    是，在绝大数情况下，人们通常会利用多余的、冗长的段落来掩盖其经营状况不好的事实。我们由此借鉴Kim的研究引入了Bloat变量。Bloat变量是由五方面决定的，分别是

\1. 词数（WC）：文本的字数；

\2. 平均句子长度（ASL）：以标点（，。！？......）为划分依据得到的文本中所有句子的平均字数；

\3. 停用词比例（SR）：指在一段文本中，停用词占总词数的比例。停用词是指在文本分析中被认为对语义贡献较小或无关紧要的词汇，通常包括常见的功能性词汇，如连词、冠词、介词、代词等；

\4. 词汇多样性（LD）：衡量文本中使用的不同词汇数量与总词汇数量之间关系的一个指标，反映了文本中词汇的丰富程度。它可以评估一段文本的语言多样性；

\5. Flesch可读性得分（FS）：是一种常用于衡量英语文本可读性和易理解程度的指标。这个评分系统通过分析句子的长度和单词的音节数来评估文本的复杂性。Flesch可读性得分越高，表示文本越容易理解；得分越低，表示文本越难理解。

我们认为这五部分对Bloat的影响是均等的，其计算公式为：

Bloat = 0.2 * ( WC + ASL + SR + LD + FS )

其中对五个因素的打分均已标准化，在-500-0区间打分。分数越高代表其冗长程度越低。若KIMI概括的摘要Bloat与公司经营指标（如利润增长率）呈正相关，则认为KIMI的概括能力是足够的。以下是结果：

**图12****：Bloat****和年销售额增长率**

![95bded70a59a40e575d72df26e3f03c](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image027.gif)

 

**图13****：Bloat****和年利润增长率**

![f3ed2a2f68ab85dab035b8fc8f13b9d](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image029.gif)

 

从结果可以看出，Bloat与年销售额增长率呈显著正相关，而与年利润增长率除个别年份外也呈正相关。这足以说明KIMI的概括能力足够让其他利益相关者快速了解公司业绩。

同时，我们也对其他模型做了类似处理。我们比较了它们的Bloat和年销售额增长率的Pearce相关系数，结果如下：

 

**图14****：三个模型的Pearce****相关系数**

![IMG_256](file:///C:/Users/Azusa/AppData/Local/Temp/msohtmlclip1/01/clip_image031.gif)

 

**4.3.4** **误差分析**

由此我们可以得出KIMI的概括能力远高于其他两者，但仍存在不足（Pearce相关系数并没有达到0.5以上），这代表尽管现在AI如此便利，站在决策者的视角，也不能完全依靠AI，更应该自己实践，翻阅并找到做决策需要的信息从而做出更正确的决策。

 

**五、结论与展望** 

**5.1** **研究总结** 

本文主要以A股上市公司上海贝岭近十年的年报文本作为研究对象，结合国产大模型生成的摘要文本与FinBERT情绪分析模型，从文本概括性、情绪分布及经营状况在统计学意义上的关联性等角度由浅入深、由表及里，分别进行了较为详细的分析。结果表明，我们所选择的三个中国主要的国产大模型对财报文本的概括能力总体较强，且概括结果具有一定逻辑。然而在具体表现上依旧存在一定差异，其中Kimi在文本精炼度和信息保留方面表现优异，而通义千问的文本精炼度在相同要求强度下较弱，文心一言则存在遗漏部分信息的现象。此外，通过情绪正负比（Positive/Negative）和冗余度（Bloat）指标的定量分析，我们能够通过与原始文本的比较进而验证Kimi概括能力的可靠性，尤其在情绪显著性和文本精炼度可以为财务报告的阅读者提供帮助。然而，尽管AI模型能够在一定程度上提供帮助，其输出仍需结合人工判断以最大程度避免重要信息遗漏。

**5.2** **应用领域** 

文章主要关注三大国产大模型在阅读与概括披露财务报告的能力，具有一定的理论和现实意义。第一，通过高效、准确的财报文本摘要生成，为投资机构、分析师以及个人投资者提供更为高效的数据支持，并通过定量分析确认生成文本的可信度，从而达到协助优化投资组合及风险管理策略的目的。第二，针对企业自身的管理与战略，企业可以更加有信心利用大模型总结内部报告，提高管理层对信息的把控能力，并以情绪分析为依据调整经营战略。第三，为金融、语言处理领域的学术研究提供了一定的理论基础，说明了利用大模型分析财报可以有实际作用，从长远角度助力教学与科研项目的开展。

**5.3** **局限性分析**

本文虽然能够在一定程度上验证了大模型作为公司披露的财务分析报告的分析工具的有效性，但仍存在若干局限性。第一，研究仅选择了一家公司作为案例分析，样本范围较小，无法全面反映不同类型企业财报的特征。第二，尽管FinBERT针对金融领域进行了预训练，但其对中文金融语境的适配仍需进一步优化，尤其是在复杂句式和隐晦情绪的识别上。第三，人工对文本重要信息的判定不可避免地带有主观性，通过情绪分析判断大模型的准确性并非完全严谨，可能在一定程度上评估结果依旧存在偏见。

**5.4** **未来展望**

本次研究存在着诸多限制和局限之处，但是对于不足之处的研究亦可以为我们提供未来发展的展望方向。首先，可以引入不同行业类别的公司作为对照研究对象，以验证大模型对不同类型财报文本的概括与分析能力，从而得到更为广泛的结论。其次，针对中文的金融语境，我们可以进一步优化预训练的选材，从而增强其对专业术语及隐性情绪的理解能力。最后，应该要加以注意在大规模应用AI大模型技术的过程中，需加强对信息透明度和准确性的监管，避免因模型局限性或误用导致决策失误。 

 

**参考文献：**

[1]Loughran, T., McDonald, B., 2014. Measuring readability in financial disclosures. *The Journal* 

*of Finance* 69, 1643–1671

[2]Dyer, T., Lang, M., Stice-Lawrence, L., 2017. The evolution of 10-k textual disclosure: Evidence from latent dirichlet allocation. *Journal of Accounting and Economics* 64, 221–245.

[3]Li, F., 2008. Annual report readability, current earnings, and earnings persistence. *Journal of* 

*Accounting and Economics* 45, 221–247

[4]Brown, S.V., Tucker, J.W., 2011. Large-sample evidence on firms’ year-over-year md&a modifications. *Journal of Accounting Research* 49, 309–346.

[5]Blankespoor, E., deHaan, E., Marinovic, I., 2020. Disclosure processing costs, investors’ information choice, and equity market outcomes: A review. *Journal of Accounting and Economics* 70, 101344.

[6]Cohen, L., Malloy, C., Nguyen, Q., 2020. Lazy prices. *The Journal of Finance* 75, 1371–1415.

[7]Kim, A.G., Muhn, M., Nikolaev, V.V., 2023. Bloated disclosures: Can chatgpt help investors process information? Available at SSRN: https://ssrn.com/abstract=4425527

[8]Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv:1810.04805. [https://doi.org/arXiv:1811.03600v2](https://doi.org/arXiv:1811.03600v2#/_blank).

[9]Lee, J., Yoon, W., Kim, S., Kim, D., Kim, S., So, C.H., Kang, J., 2019. BioBERT: A Pre-trained Biomedical Language Representation Model for Biomedical Text Mining. Bioinformatics.

[10]Huang, K., Altosaar, J., Ranganath, R., 2019. ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission. arXiv:1904.05342.

[11]Beltagy, I., Lo, K., Cohan, A., 2019. SciBERT: Pretrained Language Model for Scientific Text. In: Proceedings of EMNLP.

[12]Cui, Y., Che, W., Liu, T., Qin, B., Yang, Z., Wang, S., Hu, G., 2019. Pre-training with Whole Word Masking for Chinese BERT. arXiv:1906.08101.

[13]Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V., 2019. RoBERTa: A Robustly Optimized BERT Pre-training Approach. arXiv:1907.11692.

[14]Micikevicius, P., et al., 2017. Mixed Precision Training. arXiv:1710.03740.

[15]https://github.com/ymcui/Chinese-BERT-wwm/

[16]https://github.com/huggingface/transformers/

 

**注：**研究中用到的全部代码已上传至https://github.com/Sankarasvamin/-.git

 

 

 

------



加一些阐述（看情况）